{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Visualization\n",
    "---\n",
    "DAT 512 Canisuis College <br>\n",
    "Professor Paul Lambson<br>\n",
    "<br>\n",
    "### Learning Objectives\n",
    "- Understand theory behind group by\n",
    "- learn the group by object\n",
    "- learn how to aggregate\n",
    "- become familiar with aggregation methods\n",
    "- Pivots and cross-tabulations\n",
    "<br>\n",
    "\n",
    "\n",
    "### Sections\n",
    "- [How to Think About Group Operations](#how_to_think_about_group_operations)\n",
    "- [Data Aggregation](#data_aggregations)\n",
    "- [Apply: General split-apply-combine](#apply)\n",
    "- [Group Transforms and \"Unwrapped\" GroupBys](group_transforms_and_unwrapped_groupbys)\n",
    "- [Pivot Tables and Cross-Tabulation](#pivot_tables_and_cross_tabulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Think About Group Operations\n",
    "<a id='how_to_think_about_group_operations'></a>\n",
    "In the first stage of the process, data contained in a pandas object, whether a Series, DataFrame, or otherwise, is split into groups based on one or more keys that you provide. The splitting is performed on a particular axis of an object. For example, a DataFrame can be grouped on its rows `(axis=\"index\")` or its columns `(axis=\"columns\")`. Once this is done, a function is applied to each group, producing a new value. Finally, the results of all those function applications are combined into a result object. The form of the resulting object will usually depend on what’s being done to the data.\n",
    "![split-apply-combine](image/split-apply-combine_.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example dataframe \n",
    "df = pd.DataFrame({\"key1\" : [\"a\", \"a\", None, \"b\", \"b\", \"a\", None],\n",
    "                   \"key2\" : pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "                   \"data1\" : np.random.standard_normal(7),\n",
    "                   \"data2\" : np.random.standard_normal(7)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groupby method to create a groupby object, not calculations have beeb done yet\n",
    "grouped = df[\"data1\"].groupby(df[\"key1\"])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling an aggregation method processes the data\n",
    "grouped.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of keys can be passesd as a group key, creating a multiindex\n",
    "means = df[\"data1\"].groupby([df[\"key1\"], df[\"key2\"]]).mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot to a dataframe\n",
    "means.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map new array of correct length\n",
    "states = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\n",
    "years = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n",
    "df[\"data1\"].groupby([states, years]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequently, the grouping information is found in the same DataFrame as the data you want to work on. \n",
    "# In that case, you can pass column names (whether those are strings, numbers, or other Python objects) \n",
    "# as the group keys\n",
    "df.groupby(\"key1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key2\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"key1\", \"key2\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size produces a count like result showing group sizes\n",
    "df.groupby([\"key1\", \"key2\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNs are not counted by degault\n",
    "df.groupby(\"key1\", dropna=False).size()\n",
    "df.groupby([\"key1\", \"key2\"], dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A group function similar in spirit to size is count, \n",
    "# which computes the number of nonnull values in each group\n",
    "df.groupby(\"key1\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The object returned by groupby supports iteration\n",
    "for name, group in df.groupby(\"key1\"):\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of multiple keys, the first element in the tuple will be a tuple of key values\n",
    "for (k1, k2), group in df.groupby([\"key1\", \"key2\"]):\n",
    "    print((k1, k2))\n",
    "    print(group)\n",
    "#! blockend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary or grouped data frames, if you want to\n",
    "pieces = {name: group for name, group in df.groupby(\"key1\")}\n",
    "pieces[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix grouping axis\n",
    "grouped = df.groupby({\"key1\": \"key\", \"key2\": \"key\",\n",
    "                      \"data1\": \"data\", \"data2\": \"data\"}, axis=\"columns\")\n",
    "\n",
    "for group_key, group_values in grouped:\n",
    "    print(group_key)\n",
    "    print(group_values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a Column or Subset of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the group by object is created, a column or list of columnsc can be selected\n",
    "df.groupby([\"key1\", \"key2\"])[[\"data2\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a single column is passed as then the result groupby columns is a Series\n",
    "s_grouped = df.groupby([\"key1\", \"key2\"])[\"data2\"]\n",
    "s_grouped\n",
    "s_grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping with Dictionaries and Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=78aee68b5f504ff89e6698bd9bbec2b2\n",
    "people = pd.DataFrame(np.random.standard_normal((5, 5)),\n",
    "                      columns=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "                      index=[\"Joe\", \"Steve\", \"Wanda\", \"Jill\", \"Trey\"])\n",
    "people.iloc[2:3, [1, 2]] = np.nan # Add a few NA values\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a group correspondence for the columns and want to sum the columns by group\n",
    "mapping = {\"a\": \"red\", \"b\": \"red\", \"c\": \"blue\",\n",
    "           \"d\": \"blue\", \"e\": \"red\", \"f\" : \"orange\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mapper creates an array used for grouping\n",
    "by_column = people.groupby(mapping, axis=\"columns\")\n",
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process possible with a Series\n",
    "map_series = pd.Series(mapping)\n",
    "map_series\n",
    "people.groupby(map_series, axis=\"columns\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping with Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new array is created by evaluating the length of each row index\n",
    "people.groupby(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be combined with multiindex\n",
    "key_list = [\"one\", \"one\", \"one\", \"two\", \"two\"]\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping with Index Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dataframe for multiindex on columns\n",
    "columns = pd.MultiIndex.from_arrays([[\"US\", \"US\", \"US\", \"JP\", \"JP\"],\n",
    "                                    [1, 3, 5, 1, 3]],\n",
    "                                    names=[\"cty\", \"tenor\"])\n",
    "hier_df = pd.DataFrame(np.random.standard_normal((4, 5)), columns=columns)\n",
    "hier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass level by number or name\n",
    "hier_df.groupby(level=\"cty\", axis=\"columns\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation\n",
    "<a id='data_aggregations'></a>\n",
    "*Aggregations* refer to any data transformation that produces scalar values from arrays. The preceding examples have used several of them, including `mean`, `count`, `min`, and `sum`. You may wonder what is going on when you invoke `mean()` on a GroupBy object. Many common aggregations, such as those found in this table, have optimized implementations. However, you are not limited to only this set of methods.\n",
    "\n",
    "Funciton name | Description\n",
    ":--- | :---\n",
    "`any, all` | Return `True` if any (one or more values) or all non-NA values are “truthy”\n",
    "`count` | Number of non-NA values\n",
    "`cummin, cummax` | Cumulative minimum and maximum of non-NA values\n",
    "`cumsum` | Cumulative sum of non-NA values\n",
    "`cumprod` | Cumulative product of non-NA values\n",
    "`first, last` | First and last non-NA values\n",
    "`mean` | Mean of non-NA values\n",
    "`median` | Arithmetic median of non-NA values\n",
    "`min, max` | Minimum and maximum of non-NA values\n",
    "`nth` | Retrieve value that would appear at position n with the data in sorted order\n",
    "`ohlc` | Compute four “open-high-low-close” statistics for time series-like data\n",
    "`prod` | Product of non-NA values\n",
    "`quantile` | Compute sample quantile\n",
    "`rank` | Ordinal ranks of non-NA values, like calling Series.rank\n",
    "`size` | Compute group sizes, returning result as a Series\n",
    "`sum` |  Sum of non-NA values\n",
    "`std, var`| Sample standard deviation and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a groupby object and pass an argument needed for nsmallest\n",
    "df\n",
    "grouped = df.groupby(\"key1\")\n",
    "grouped[\"data1\"].nsmallest(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDFs can be passed, will perform more slowly\n",
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "grouped.agg(peak_to_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# love to see descriptive statistics\n",
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column-Wise and Multiple Function Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in tips dataset\n",
    "tips = pd.read_csv(\"examples/tips.csv\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tips percentage\n",
    "tips[\"tip_pct\"] = tips[\"tip\"] / tips[\"total_bill\"]\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a groupby object with columns, rather than index \n",
    "grouped = tips.groupby([\"day\", \"smoker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a single string function name, get a Series\n",
    "grouped_pct = grouped[\"tip_pct\"]\n",
    "grouped_pct.agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a list of aggregators, get a DataFrame\n",
    "grouped_pct.agg([\"mean\", \"std\", peak_to_peak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass tuples to rename with custom names rather than function names\n",
    "grouped_pct.agg([(\"average\", \"mean\"), (\"stdev\", np.std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a list of functions to apply to all columns\n",
    "functions = [\"count\", \"mean\", \"max\"]\n",
    "result = grouped[[\"tip_pct\", \"total_bill\"]].agg(functions)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=48aeddf0d8614a9daa16851bf8292777\n",
    "result[\"tip_pct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples that indicate names can be passed\n",
    "ftuples = [(\"Average\", \"mean\"), (\"Variance\", np.var)]\n",
    "grouped[[\"tip_pct\", \"total_bill\"]].agg(ftuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary can be used to specify aggregation by column\n",
    "grouped.agg({\"tip\" : np.max, \"size\" : \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg({\"tip_pct\" : [\"min\", \"max\", \"mean\", \"std\"],\n",
    "             \"size\" : \"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returning Aggregated Data Without Row Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass an agrument to supress groupby column to be the new idnex\n",
    "tips.groupby([\"day\", \"smoker\"], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply: General split-apply-combine\n",
    "<a id='apply'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that works with a dataframe\n",
    "def top(df, n=5, column=\"tip_pct\"):\n",
    "    return df.sort_values(column, ascending=False)[:n]\n",
    "top(tips, n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to each group\n",
    "tips.groupby(\"smoker\").apply(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with keyword agruments\n",
    "tips.groupby([\"smoker\", \"day\"]).apply(top, n=1, column=\"total_bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can apply group by easily\n",
    "result = tips.groupby(\"smoker\")[\"tip_pct\"].describe()\n",
    "result\n",
    "result.unstack(\"smoker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supressing the Group Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surpess by keyword\n",
    "tips.groupby(\"smoker\", group_keys=False).apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile and Bucket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=b9e64e9337f247c0a408ea0c7a9961c5\n",
    "frame = pd.DataFrame({\"data1\": np.random.standard_normal(1000),\n",
    "                      \"data2\": np.random.standard_normal(1000)})\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiles = pd.cut(frame[\"data1\"], 4)\n",
    "quartiles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish a custom stats function\n",
    "def get_stats(group):\n",
    "    return pd.DataFrame(\n",
    "        {\"min\": group.min(), \"max\": group.max(),\n",
    "        \"count\": group.count(), \"mean\": group.mean()}\n",
    "    )\n",
    "\n",
    "grouped = frame.groupby(quartiles)\n",
    "# apply it to the groupby object\n",
    "grouped.apply(get_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but look how easy it could be\n",
    "grouped.agg([\"min\", \"max\", \"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for similar population sized buckets\n",
    "quartiles_samp = pd.qcut(frame[\"data1\"], 4, labels=False)\n",
    "quartiles_samp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at counts, evenly sized group, varying on ranges\n",
    "grouped = frame.groupby(quartiles_samp)\n",
    "grouped.apply(get_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Filling Missing Values with Group-Specific Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=a5f76377f0184195828c907897eb39d1\n",
    "s = pd.Series(np.random.standard_normal(6))\n",
    "s[::2] = np.nan\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(s.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=b4f45efcbdd0491f906ca6a4847bab1e\n",
    "states = [\"Ohio\", \"New York\", \"Vermont\", \"Florida\",\n",
    "          \"Oregon\", \"Nevada\", \"California\", \"Idaho\"]\n",
    "group_key = [\"East\", \"East\", \"East\", \"East\",\n",
    "             \"West\", \"West\", \"West\", \"West\"]\n",
    "data = pd.Series(np.random.standard_normal(8), index=states)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=72f2656d298f413f8720b68b62b51674\n",
    "data[[\"Vermont\", \"Nevada\", \"Idaho\"]] = np.nan\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(group_key).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create UDF \n",
    "def fill_mean(group):\n",
    "    return group.fillna(group.mean())\n",
    "\n",
    "data.groupby(group_key).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined fill values\n",
    "fill_values = {\"East\": 0.5, \"West\": -1}\n",
    "def fill_func(group):\n",
    "    return group.fillna(fill_values[group.name])\n",
    "\n",
    "data.groupby(group_key).apply(fill_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Random Sampling and Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deck of cards\n",
    "suits = [\"H\", \"S\", \"C\", \"D\"]  # Hearts, Spades, Clubs, Diamonds\n",
    "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
    "base_names = [\"A\"] + list(range(2, 11)) + [\"J\", \"K\", \"Q\"]\n",
    "cards = []\n",
    "for suit in suits:\n",
    "    cards.extend(str(num) + suit for num in base_names)\n",
    "\n",
    "deck = pd.Series(card_val, index=cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=d54e45a5b95f4e84ab900beaeffc032e\n",
    "deck.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing a 5 card hand\n",
    "def draw(deck, n=5):\n",
    "    return deck.sample(n)\n",
    "draw(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you wanted 2 cards from each suit\n",
    "def get_suit(card):\n",
    "    # last letter is suit\n",
    "    return card[-1]\n",
    "\n",
    "deck.groupby(get_suit).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now dropping keys\n",
    "deck.groupby(get_suit, group_keys=False).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Group Weighted Average and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df = pd.DataFrame({\"category\": [\"a\", \"a\", \"a\", \"a\",\n",
    "                                \"b\", \"b\", \"b\", \"b\"],\n",
    "                   \"data\": np.random.standard_normal(8),\n",
    "                   \"weights\": np.random.uniform(size=8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weighted average by category would then be\n",
    "grouped = df.groupby(\"category\")\n",
    "def get_wavg(group):\n",
    "    return np.average(group[\"data\"], weights=group[\"weights\"])\n",
    "\n",
    "grouped.apply(get_wavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in stock data\n",
    "close_px = pd.read_csv(\"examples/stock_px.csv\", parse_dates=True,\n",
    "                       index_col=0)\n",
    "close_px.info()\n",
    "close_px.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise correlation with a column\n",
    "def spx_corr(group):\n",
    "    return group.corrwith(group[\"SPX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute percent change on close_px using pct_change\n",
    "rets = close_px.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a year to group by then \n",
    "def get_year(x):\n",
    "    return x.year\n",
    "\n",
    "by_year = rets.groupby(get_year)\n",
    "by_year.apply(spx_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter column correlation\n",
    "def corr_aapl_msft(group):\n",
    "    return group[\"AAPL\"].corr(group[\"MSFT\"])\n",
    "by_year.apply(corr_aapl_msft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Group-Wise Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in a linear model\n",
    "import statsmodels.api as sm\n",
    "def regress(data, yvar=None, xvars=None):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    X[\"intercept\"] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find coefficients per group\n",
    "by_year.apply(regress, yvar=\"AAPL\", xvars=[\"SPX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Transforms and “Unwrapped” GroupBys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dataframe\n",
    "df = pd.DataFrame({'key': ['a', 'b', 'c'] * 4,\n",
    "                   'value': np.arange(12.)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group means by key:\n",
    "g = df.groupby('key')['value']\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can pass a function that computes the mean of a single group to transform\n",
    "def get_mean(group):\n",
    "    return group.mean()\n",
    "g.transform(get_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also call by function name as a string\n",
    "g.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual calculation by group\n",
    "def times_two(group):\n",
    "    return group * 2\n",
    "g.transform(times_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ranks in descending order for each group\n",
    "def get_ranks(group):\n",
    "    return group.rank(ascending=False)\n",
    "g.transform(get_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple normalize\n",
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=d06c11e725f744abb0b0309eb2c04526\n",
    "g.transform(normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ipython id=36f1cd239f9a4b218ea0d3dc86776890\n",
    "g.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = (df['value'] - g.transform('mean')) / g.transform('std')\n",
    "normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables and Cross-Tabulation\n",
    "<a id='group_transforms_and_unwrapped_groupbys'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in tips dataset\n",
    "tips = pd.read_csv(\"examples/tips.csv\")\n",
    "tips[\"tip_pct\"] = tips[\"tip\"] / tips[\"total_bill\"]\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.pivot_table(index=[\"day\", \"smoker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  could augment this table to include partial totals by passing margins=True\n",
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n",
    "                 values=[\"tip_pct\", \"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could augment this table to include partial totals by passing margins=True\n",
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n",
    "                 values=[\"tip_pct\", \"size\"], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could pass an agg function\n",
    "tips.pivot_table(index=[\"time\", \"smoker\"], columns=\"day\",\n",
    "                 values=\"tip_pct\", aggfunc=len, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could fill na values\n",
    "tips.pivot_table(index=[\"time\", \"size\", \"smoker\"], columns=\"day\",\n",
    "                 values=\"tip_pct\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Tabulations: Crosstab\n",
    "<a id='pivot_tables_and_cross_tabulations'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in some data\n",
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"Sample  Nationality  Handedness\n",
    "1   USA  Right-handed\n",
    "2   Japan    Left-handed\n",
    "3   USA  Right-handed\n",
    "4   Japan    Right-handed\n",
    "5   Japan    Left-handed\n",
    "6   Japan    Right-handed\n",
    "7   USA  Right-handed\n",
    "8   USA  Left-handed\n",
    "9   Japan    Right-handed\n",
    "10  USA  Right-handed\"\"\"\n",
    "\n",
    "data = pd.read_table(StringIO(data), sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the indexes\n",
    "pd.crosstab(data[\"Nationality\"], data[\"Handedness\"], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of indexes for hierarhcy\n",
    "pd.crosstab([tips[\"time\"], tips[\"day\"]], tips[\"smoker\"], margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
